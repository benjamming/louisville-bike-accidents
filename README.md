# louisville-bike-accidents

## Quick Start

Create a virtual environment to install modules.
Use pip install -r requirements.txt to install required modules.
    Modules required: 
Run the Python files in 02_cleaning directory.
    The files prefixed by `01` can be run in any order, but these must be run before `02_merge_accident_data.py`. 
Open and run `03_analysis.ipynb`

## Source data
### directory: /data/raw

The source data for my project. 

Since I am dealing with multiple datasets, I use a short "codename" for each file. In various scripts, you will see `LOJIC`, `CSAFE`, or `SIGNALS` as a variable name for the Dataframes, or other data objects I use to keep track of and manipulate the source data. 

| codename | file name: data/raw/... | description |
|----------|-----------|-------------|
| LOJIC | Louisville_Metro_KY_-_Traffic_Fatalities_and_Suspected_Serious_Injuries.csv | Crash reports from 2016-2023 (Updated regularly) in Jefferson County, KY. This data was found on the Louisville Open Data portal. It includes reports of all crashes during its timeframe. This includes motor vehicle crashes and pedestrian incidents. |
| CSAFE | cycling_safety_louisville.csv | Crash reports from 2010-2017. This data was part of a European study on cycling safety. |
| SIGNALS | Jefferson_County_KY_Signalized_Intersections.csv | Road intersections in Jefferson County, KY which have traffic lights. |

## Discovery
### directory: /code/discovery

Jupyter notebooks for data discovery on this project's source data. 

| codename | notebook name |
|----------|---------------|
| LOJIC | discovery_LOJIC.ipynb |
| CSAFE | discovery_cycling_safety.ipynb |
| SIGNALS | other_discovery.ipynb |

`other_discovery.ipynb` expects `cycling_safety_louisville_cleaned.csv` to exist. An exception will be raised if that file cannot be found. Please run `01_cleaning_cycling_safety.py` before you try to run the cells in this notebook. However, this notebook was only used to test some code that ended up in `02_merge_accident.py`. It's not necessary to run the notebook project analysis to work. Only the Pytho files in `02_cleaning/` are necessary. I only left this notebook in to show my development process.

## Cleaning

### cleaning scripts directory: /code/cleaning
### precleaned data directory: /data/preclean

For each of the source datasets, I first did some cleaning to remove unwanted data and make these easier to combine. This directory contains the resulting .csv files from that cleaning process.

Run `python {cleaning file}` to generate a clean(er) CSV for each source file. (These can be run in any order.)

| codename | clean CSV name: data/preclean/... | cleaning script code/cleaning/... |source file |
|----------|----------------|-----------------|------------|
| LOJIC | LOJIC_cycling_data.csv | cleaning/01_cleaning_LOJIC.py | data/raw/Louisville_Metro_KY_-_Traffic_Fatalities_and_Suspected_Serious_Injuries.csv|
| CSAFE | cycling_safety_louisville_clean.csv | 01_cleaning_cycling_safety.py | data/raw/cycling_safety_louisville.csv |
|  | bike_accidents.csv | 02_merge_accident_data.py | preclean/cycling_safety_louisville_cleaned.csv, preclean/LOJIC_cycling_data_cleaned.csv |

`02_merge_acident_data.py` expects the CSV files in `preclean/` to exist. Run `python 02_cleaning/01*` first.

### final cleaning steps: /data/clean

Final clean data I can use for analysis. This directory contains one CSV file which is generated by `code/cleaning/02_merge_accident_data.py`. This CSV file is called `bike_accidents.csv`

The directory also includes data_dictionary.md, a markdown file with a data dictionary explaining the cleaned data.

## Analysis

# Requirements

These are the parts of my projects which satisfy the requirements for the Code:You / Code Louisville Data Analytics Pathway.

| Requirement Section | |
|---------------------|-|
| 1. Loading data | |
| 2. Clean and operate on data | |
| 3. Visualize data || 
| 4. Best practices ||
| 5. Interpretation of data || 
